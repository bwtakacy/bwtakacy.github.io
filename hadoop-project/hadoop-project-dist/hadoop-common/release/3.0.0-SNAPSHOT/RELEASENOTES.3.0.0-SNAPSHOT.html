<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!--
 | Generated by Apache Maven Doxia at 2016-05-30
 | Rendered using Apache Maven Stylus Skin 1.5
-->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Apache Hadoop 3.0.0-alpha1-SNAPSHOT &#x2013; Apache Hadoop 3.0.0-SNAPSHOT Release Notes</title>
    <style type="text/css" media="all">
      @import url("../../css/maven-base.css");
      @import url("../../css/maven-theme.css");
      @import url("../../css/site.css");
    </style>
    <link rel="stylesheet" href="../../css/print.css" type="text/css" media="print" />
        <meta name="Date-Revision-yyyymmdd" content="20160530" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
                </head>
  <body class="composite">
    <div id="banner">
                        <a href="http://hadoop.apache.org/" id="bannerLeft">
                                        <img src="http://hadoop.apache.org/images/hadoop-logo.jpg" alt="" />
                </a>
                              <a href="http://www.apache.org/" id="bannerRight">
                                        <img src="http://www.apache.org/images/asf_logo_wide.png" alt="" />
                </a>
            <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="breadcrumbs">
            
                                   <div class="xleft">
                          <a href="http://www.apache.org/" class="externalLink">Apache</a>
        &gt;
                  <a href="http://hadoop.apache.org/" class="externalLink">Hadoop</a>
        &gt;
                  <a href="../../../index.html">Apache Hadoop Project Dist POM</a>
        &gt;
                  <a href="../../index.html">Apache Hadoop 3.0.0-alpha1-SNAPSHOT</a>
        &gt;
        Apache Hadoop 3.0.0-SNAPSHOT Release Notes
        </div>
            <div class="xright">            <a href="http://wiki.apache.org/hadoop" class="externalLink">Wiki</a>
            |
                <a href="https://git-wip-us.apache.org/repos/asf/hadoop.git" class="externalLink">git</a>
            |
                <a href="http://hadoop.apache.org/" class="externalLink">Apache Hadoop</a>
              
                                   &nbsp;| Last Published: 2016-05-30
              &nbsp;| Version: 3.0.0-alpha1-SNAPSHOT
            </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="leftColumn">
      <div id="navcolumn">
             
                                                   <h5>General</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../../index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/SingleCluster.html">Single Node Setup</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/ClusterSetup.html">Cluster Setup</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/CommandsManual.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/FileSystemShell.html">FileSystem Shell</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/Compatibility.html">Compatibility</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/InterfaceClassification.html">Interface Classification</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/filesystem/index.html">FileSystem Specification</a>
            </li>
          </ul>
                       <h5>Common</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/CLIMiniCluster.html">CLI Mini Cluster</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/NativeLibraries.html">Native Libraries</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/Superusers.html">Proxy User</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/RackAwareness.html">Rack Awareness</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/SecureMode.html">Secure Mode</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/ServiceLevelAuth.html">Service Level Authorization</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/HttpAuthentication.html">HTTP Authentication</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/CredentialProviderAPI.html">Credential Provider API</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-kms/index.html">Hadoop KMS</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/Tracing.html">Tracing</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/UnixShellGuide.html">Unix Shell Guide</a>
            </li>
          </ul>
                       <h5>HDFS</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">Architecture</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">User Guide</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HDFSCommands.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">NameNode HA With QJM</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html">NameNode HA With NFS</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/Federation.html">Federation</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/ViewFs.html">ViewFs</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HdfsSnapshots.html">Snapshots</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HdfsEditsViewer.html">Edits Viewer</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HdfsImageViewer.html">Image Viewer</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html">Permissions and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HdfsQuotaAdminGuide.html">Quotas and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/LibHdfs.html">libhdfs (C API)</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/WebHDFS.html">WebHDFS (REST API)</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-hdfs-httpfs/index.html">HttpFS</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html">Short Circuit Local Reads</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/CentralizedCacheManagement.html">Centralized Cache Management</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HdfsNfsGateway.html">NFS Gateway</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html">Rolling Upgrade</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/ExtendedAttributes.html">Extended Attributes</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html">Transparent Encryption</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HdfsMultihoming.html">Multihoming</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html">Storage Policies</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/MemoryStorage.html">Memory Storage Support</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/SLGUserGuide.html">Synthetic Load Generator</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html">Erasure Coding</a>
            </li>
          </ul>
                       <h5>MapReduce</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">Tutorial</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredCommands.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduce_Compatibility_Hadoop1_Hadoop2.html">Compatibility with 1.x</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/EncryptedShuffle.html">Encrypted Shuffle</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/PluggableShuffleAndPluggableSort.html">Pluggable Shuffle/Sort</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/DistributedCacheDeploy.html">Distributed Cache Deploy</a>
            </li>
          </ul>
                       <h5>MapReduce REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredAppMasterRest.html">MR Application Master</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-mapreduce-client/hadoop-mapreduce-client-hs/HistoryServerRest.html">MR History Server</a>
            </li>
          </ul>
                       <h5>YARN</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/YARN.html">Architecture</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/YarnCommands.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html">Capacity Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/FairScheduler.html">Fair Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/ResourceManagerRestart.html">ResourceManager Restart</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html">ResourceManager HA</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/NodeLabel.html">Node Labels</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/WebApplicationProxy.html">Web Application Proxy</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/TimelineServer.html">Timeline Server</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html">Writing YARN Applications</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/YarnApplicationSecurity.html">YARN Application Security</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/NodeManager.html">NodeManager</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/DockerContainerExecutor.html">DockerContainerExecutor</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/NodeManagerCgroups.html">Using CGroups</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/SecureContainer.html">Secure Containers</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/registry/index.html">Registry</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/ReservationSystem.html">Reservation System</a>
            </li>
          </ul>
                       <h5>YARN REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/WebServicesIntro.html">Introduction</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html">Resource Manager</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/NodeManagerRest.html">Node Manager</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-site/TimelineServer.html#Timeline_Server_REST_API_v1">Timeline Server</a>
            </li>
          </ul>
                       <h5>Hadoop Compatible File Systems</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../../hadoop-aws/tools/hadoop-aws/index.html">Amazon S3</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-azure/index.html">Azure Blob Storage</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-openstack/index.html">OpenStack Swift</a>
            </li>
          </ul>
                       <h5>Auth</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../../hadoop-auth/index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-auth/Examples.html">Examples</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-auth/Configuration.html">Configuration</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-auth/BuildingIt.html">Building</a>
            </li>
          </ul>
                       <h5>Tools</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../../hadoop-streaming/HadoopStreaming.html">Hadoop Streaming</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-archives/HadoopArchives.html">Hadoop Archives</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-archive-logs/HadoopArchiveLogs.html">Hadoop Archive Logs</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-distcp/DistCp.html">DistCp</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-gridmix/GridMix.html">GridMix</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-rumen/Rumen.html">Rumen</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-sls/SchedulerLoadSimulator.html">Scheduler Load Simulator</a>
            </li>
          </ul>
                       <h5>Reference</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/release/index.html">Changelog and Release Notes</a>
            </li>
                  <li class="none">
                  <a href="../../../../api/index.html">Java API docs</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/UnixShellAPI.html">Unix Shell API</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/Metrics.html">Metrics</a>
            </li>
          </ul>
                       <h5>Configuration</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/core-default.xml">core-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">hdfs-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml">mapred-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../../hadoop-project-dist/hadoop-common/DeprecatedProperties.html">Deprecated Properties</a>
            </li>
          </ul>
                                 <a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy">
          <img alt="Built by Maven" src="../../images/logos/maven-feather.png"/>
        </a>
                       
                               </div>
    </div>
    <div id="bodyColumn">
      <div id="contentBox">
        <!---
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
--><h1>&#x201c;Apache Hadoop&#x201d; 3.0.0-SNAPSHOT Release Notes</h1>
<p>These release notes cover new developer and user-facing incompatibilities, important issues, features, and major improvements.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-13045">HADOOP-13045</a> | <i>Major</i> | <b>hadoop_add_classpath is not working in .hadooprc</b></li>
</ul>
<!-- markdown -->
<p>With this change, the <tt>.hadooprc</tt> file is now processed after Apache Hadoop has been fully bootstrapped. This allows for usage of the Apache Hadoop Shell API. A new file, <tt>.hadoop-env</tt>, now provides the ability for end users to override <tt>hadoop-env.sh</tt>.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-12967">HADOOP-12967</a> | <i>Major</i> | <b>Remove FileUtil#copyMerge</b></li>
</ul>
<p>Removed FileUtil.copyMerge.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-12857">HADOOP-12857</a> | <i>Major</i> | <b>Rework hadoop-tools</b></li>
</ul>
<!-- markdown -->

<ul>
  
<li>Turning on optional things from the tools directory can now be done via hadoop-env.sh without impacting the various user-facing CLASSPATH.</li>
  
<li>The tools directory is no longer pulled in blindly for any utilities that pull it in.</li>
  
<li>TOOL_PATH / HADOOP_TOOLS_PATH has been broken apart and replaced with HADOOP_TOOLS_HOME, HADOOP_TOOLS_DIR and HADOOP_TOOLS_LIB_JARS_DIR to be consistent with the rest of Hadoop.</li>
</ul>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-12850">HADOOP-12850</a> | <i>Major</i> | <b>pull shell code out of hadoop-dist</b></li>
</ul>
<p>This change contains the content of HADOOP-10115 which is an incompatible change.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-12811">HADOOP-12811</a> | <i>Critical</i> | <b>Change kms server port number which conflicts with HMaster port number</b></li>
</ul>
<p>The default port for KMS service is now 9600. This is to avoid conflicts on the previous port 16000, which is also used by HMaster as the default port.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-12563">HADOOP-12563</a> | <i>Major</i> | <b>Updated utility to create/modify token files</b></li>
</ul>
<p>This feature introduces a new command called &#x201c;hadoop dtutil&#x201d; which lets users request and download delegation tokens with certain attributes.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-12504">HADOOP-12504</a> | <i>Blocker</i> | <b>Remove metrics v1</b></li>
</ul>
<!-- markdown -->

<ul>
  
<li>org.apache.hadoop.metrics package was removed. Use org.apache.hadoop.metrics2 package instead.</li>
  
<li>&#x201c;/metrics&#x201d; endpoint was removed. Use &#x201c;/jmx&#x201d; instead to see the metrics.</li>
</ul>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-12495">HADOOP-12495</a> | <i>Major</i> | <b>Fix posix_spawn error on OS X</b></li>
</ul>
<p>When Hadoop JVMs create other processes on OS X, it will always use posix_spawn.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-12493">HADOOP-12493</a> | <i>Major</i> | <b>bash unit tests are failing</b></li>
</ul>
<p>In the extremely rare event that HADOOP_USER_IDENT and USER environment variables are not defined, we now fall back to use &#x2018;hadoop&#x2019; as the identification string.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-12294">HADOOP-12294</a> | <i>Major</i> | <b>Throw an Exception when fs.permissions.umask-mode is misconfigured</b></li>
</ul>
<p>The support of the deprecated dfs.umask key is removed in Hadoop 3.0.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-11781">HADOOP-11781</a> | <i>Major</i> | <b>fix race conditions and add URL support to smart-apply-patch.sh</b></li>
</ul>
<p>Now auto-downloads patch from issue-id; fixed race conditions; fixed bug affecting some patches.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-11698">HADOOP-11698</a> | <i>Major</i> | <b>Remove DistCpV1 and Logalyzer</b></li>
</ul>
<p>Removed DistCpV1 and Logalyzer.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-11657">HADOOP-11657</a> | <i>Minor</i> | <b>Align the output of <tt>hadoop fs -du</tt> to be more Unix-like</b></li>
</ul>
<p>The output of du has now been made more Unix-like, with aligned output.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-11627">HADOOP-11627</a> | <i>Major</i> | <b>Remove io.native.lib.available</b></li>
</ul>
<p>io.native.lib.available was removed. Always use native libraries if they exist.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-11554">HADOOP-11554</a> | <i>Major</i> | <b>Expose HadoopKerberosName as a hadoop subcommand</b></li>
</ul>
<p>The hadoop kerbname subcommand has been added to ease operational pain in determining the output of auth_to_local rules.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-11553">HADOOP-11553</a> | <i>Blocker</i> | <b>Formalize the shell API</b></li>
</ul>
<p>Python is now required to build the documentation.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-11460">HADOOP-11460</a> | <i>Major</i> | <b>Deprecate shell vars</b></li>
</ul>
<!-- markdown -->

<table border="0" class="bodyTable">
  <thead>
    
<tr class="a">
      
<th align="left">Old </th>
      
<th align="left">New </th>
    </tr>
  </thead>
  <tbody>
    
<tr class="b">
      
<td align="left">HADOOP_HDFS_LOG_DIR </td>
      
<td align="left">HADOOP_LOG_DIR </td>
    </tr>
    
<tr class="a">
      
<td align="left">HADOOP_HDFS_LOGFILE </td>
      
<td align="left">HADOOP_LOGFILE </td>
    </tr>
    
<tr class="b">
      
<td align="left">HADOOP_HDFS_NICENESS </td>
      
<td align="left">HADOOP_NICENESS </td>
    </tr>
    
<tr class="a">
      
<td align="left">HADOOP_HDFS_STOP_TIMEOUT </td>
      
<td align="left">HADOOP_STOP_TIMEOUT </td>
    </tr>
    
<tr class="b">
      
<td align="left">HADOOP_HDFS_PID_DIR </td>
      
<td align="left">HADOOP_PID_DIR </td>
    </tr>
    
<tr class="a">
      
<td align="left">HADOOP_HDFS_ROOT_LOGGER </td>
      
<td align="left">HADOOP_ROOT_LOGGER </td>
    </tr>
    
<tr class="b">
      
<td align="left">HADOOP_HDFS_IDENT_STRING </td>
      
<td align="left">HADOOP_IDENT_STRING </td>
    </tr>
    
<tr class="a">
      
<td align="left">HADOOP_MAPRED_LOG_DIR </td>
      
<td align="left">HADOOP_LOG_DIR </td>
    </tr>
    
<tr class="b">
      
<td align="left">HADOOP_MAPRED_LOGFILE </td>
      
<td align="left">HADOOP_LOGFILE </td>
    </tr>
    
<tr class="a">
      
<td align="left">HADOOP_MAPRED_NICENESS </td>
      
<td align="left">HADOOP_NICENESS </td>
    </tr>
    
<tr class="b">
      
<td align="left">HADOOP_MAPRED_STOP_TIMEOUT </td>
      
<td align="left">HADOOP_STOP_TIMEOUT </td>
    </tr>
    
<tr class="a">
      
<td align="left">HADOOP_MAPRED_PID_DIR </td>
      
<td align="left">HADOOP_PID_DIR </td>
    </tr>
    
<tr class="b">
      
<td align="left">HADOOP_MAPRED_ROOT_LOGGER </td>
      
<td align="left">HADOOP_ROOT_LOGGER </td>
    </tr>
    
<tr class="a">
      
<td align="left">HADOOP_MAPRED_IDENT_STRING </td>
      
<td align="left">HADOOP_IDENT_STRING </td>
    </tr>
    
<tr class="b">
      
<td align="left">YARN_CONF_DIR </td>
      
<td align="left">HADOOP_CONF_DIR </td>
    </tr>
    
<tr class="a">
      
<td align="left">YARN_LOG_DIR </td>
      
<td align="left">HADOOP_LOG_DIR </td>
    </tr>
    
<tr class="b">
      
<td align="left">YARN_LOGFILE </td>
      
<td align="left">HADOOP_LOGFILE </td>
    </tr>
    
<tr class="a">
      
<td align="left">YARN_NICENESS </td>
      
<td align="left">HADOOP_NICENESS </td>
    </tr>
    
<tr class="b">
      
<td align="left">YARN_STOP_TIMEOUT </td>
      
<td align="left">HADOOP_STOP_TIMEOUT </td>
    </tr>
    
<tr class="a">
      
<td align="left">YARN_PID_DIR </td>
      
<td align="left">HADOOP_PID_DIR </td>
    </tr>
    
<tr class="b">
      
<td align="left">YARN_ROOT_LOGGER </td>
      
<td align="left">HADOOP_ROOT_LOGGER </td>
    </tr>
    
<tr class="a">
      
<td align="left">YARN_IDENT_STRING </td>
      
<td align="left">HADOOP_IDENT_STRING </td>
    </tr>
    
<tr class="b">
      
<td align="left">YARN_OPTS </td>
      
<td align="left">HADOOP_OPTS </td>
    </tr>
    
<tr class="a">
      
<td align="left">YARN_SLAVES </td>
      
<td align="left">HADOOP_SLAVES </td>
    </tr>
    
<tr class="b">
      
<td align="left">YARN_USER_CLASSPATH </td>
      
<td align="left">HADOOP_USER_CLASSPATH </td>
    </tr>
    
<tr class="a">
      
<td align="left">YARN_USER_CLASSPATH_FIRST </td>
      
<td align="left">HADOOP_USER_CLASSPATH_FIRST </td>
    </tr>
    
<tr class="b">
      
<td align="left">KMS_CONFIG </td>
      
<td align="left">HADOOP_CONF_DIR </td>
    </tr>
    
<tr class="a">
      
<td align="left">KMS_LOG </td>
      
<td align="left">HADOOP_LOG_DIR </td>
    </tr>
  </tbody>
</table>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-11393">HADOOP-11393</a> | <i>Major</i> | <b>Revert HADOOP_PREFIX, go back to HADOOP_HOME</b></li>
</ul>
<p>On Unix platforms, HADOOP_PREFIX has been deprecated in favor of returning to HADOOP_HOME as in prior Apache Hadoop releases.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-11356">HADOOP-11356</a> | <i>Major</i> | <b>Removed deprecated o.a.h.fs.permission.AccessControlException</b></li>
</ul>
<p>org.apache.hadoop.fs.permission.AccessControlException was deprecated in the last major release, and has been removed in favor of org.apache.hadoop.security.AccessControlException</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-11353">HADOOP-11353</a> | <i>Major</i> | <b>Add support for .hadooprc</b></li>
</ul>
<p>.hadooprc allows users a convenient way to set and/or override the shell level settings.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-11041">HADOOP-11041</a> | <i>Minor</i> | <b>VersionInfo output specifies subversion</b></li>
</ul>
<p>This changes the output of the &#x2018;hadoop version&#x2019; command to generically say &#x2018;Source code repository&#x2019; rather than specify which type of repo.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-10950">HADOOP-10950</a> | <i>Major</i> | <b>rework heap management vars</b></li>
</ul>
<!-- markdown -->

<ul>
  
<li>
<p>HADOOP_HEAPSIZE variable has been deprecated (It will still be honored if set, but expect it to go away in the future). In its place, HADOOP_HEAPSIZE_MAX and HADOOP_HEAPSIZE_MIN have been introduced to set Xmx and Xms, respectively.</p></li>
  
<li>
<p>The internal variable JAVA_HEAP_MAX has been removed.</p></li>
  
<li>
<p>Default heap sizes have been removed. This will allow for the JVM to use auto-tuning based upon the memory size of the host. To re-enable the old default, configure HADOOP_HEAPSIZE_MAX=&#x201c;1g&#x201d; in hadoop-env.sh. </p></li>
  
<li>
<p>All global and daemon-specific heap size variables now support units. If the variable is only a number, the size is assumed to be in megabytes.</p></li>
</ul>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-10787">HADOOP-10787</a> | <i>Blocker</i> | <b>Rename/remove non-HADOOP_*, etc from the shell scripts</b></li>
</ul>
<!-- markdown -->
<p>The following shell environment variables have been deprecated:</p>

<table border="0" class="bodyTable">
  <thead>
    
<tr class="a">
      
<th align="left">Old </th>
      
<th align="left">New </th>
    </tr>
  </thead>
  <tbody>
    
<tr class="b">
      
<td align="left">DEFAULT_LIBEXEC_DIR </td>
      
<td align="left">HADOOP_DEFAULT_LIBEXEC_DIR </td>
    </tr>
    
<tr class="a">
      
<td align="left">SLAVE_NAMES </td>
      
<td align="left">HADOOP_SLAVE_NAMES </td>
    </tr>
    
<tr class="b">
      
<td align="left">TOOL_PATH </td>
      
<td align="left">HADOOP_TOOLS_PATH </td>
    </tr>
  </tbody>
</table>
<p>In addition:</p>

<ul>
  
<li>DEFAULT_LIBEXEC_DIR will NOT be automatically transitioned to HADOOP_DEFAULT_LIBEXEC_DIR and will require changes to any scripts setting that value. A warning will be printed to the screen if DEFAULT_LIBEXEC_DIR has been configured.</li>
  
<li>HADOOP_TOOLS_PATH is now properly handled as a multi-valued, Java classpath-style variable. Prior, multiple values assigned to TOOL_PATH would not work a predictable manner.</li>
</ul>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-10474">HADOOP-10474</a> | <i>Major</i> | <b>Move o.a.h.record to hadoop-streaming</b></li>
</ul>
<p><b>WARNING: No release note provided for this incompatible change.</b></p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-10115">HADOOP-10115</a> | <i>Major</i> | <b>Exclude duplicate jars in hadoop package under different component&#x2019;s lib</b></li>
</ul>
<p>Jars in the various subproject lib directories are now de-duplicated against Hadoop common. Users who interact directly with those directories must be sure to pull in common&#x2019;s dependencies as well.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-9905">HADOOP-9905</a> | <i>Major</i> | <b>remove dependency of zookeeper for hadoop-client</b></li>
</ul>
<p>Zookeeper jar removed from hadoop-client dependency tree.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-9902">HADOOP-9902</a> | <i>Major</i> | <b>Shell script rewrite</b></li>
</ul>
<!-- markdown -->
<p>The Hadoop shell scripts have been rewritten to fix many long standing bugs and include some new features. While an eye has been kept towards compatibility, some changes may break existing installations.</p>
<p>INCOMPATIBLE CHANGES:</p>

<ul>
  
<li>The pid and out files for secure daemons have been renamed to include the appropriate ${HADOOP_IDENT_STR}. This should allow, with proper configurations in place, for multiple versions of the same secure daemon to run on a host. Additionally, pid files are now created when daemons are run in interactive mode. This will also prevent the accidental starting of two daemons with the same configuration prior to launching java (i.e., &#x201c;fast fail&#x201d; without having to wait for socket opening).</li>
  
<li>All Hadoop shell script subsystems now execute hadoop-env.sh, which allows for all of the environment variables to be in one location. This was not the case previously.</li>
  
<li>The default content of *-env.sh has been significantly altered, with the majority of defaults moved into more protected areas inside the code. Additionally, these files do not auto-append anymore; setting a variable on the command line prior to calling a shell command must contain the entire content, not just any extra settings. This brings Hadoop more in-line with the vast majority of other software packages.</li>
  
<li>All HDFS_*, YARN_*, and MAPRED_* environment variables act as overrides to their equivalent HADOOP_* environment variables when &#x2018;hdfs&#x2019;, &#x2018;yarn&#x2019;, &#x2018;mapred&#x2019;, and related commands are executed. Previously, these were separated out which meant a significant amount of duplication of common settings.</li>
  
<li>hdfs-config.sh and hdfs-config.cmd were inadvertently duplicated into libexec and sbin. The sbin versions have been removed.</li>
  
<li>The log4j settings forcibly set by some *-daemon.sh commands have been removed. These settings are now configurable in the *-env.sh files via *_OPT.</li>
  
<li>Support for various undocumented YARN log4j.properties files has been removed.</li>
  
<li>Support for ${HADOOP_MASTER} and the related rsync code have been removed.</li>
  
<li>The undocumented and unused yarn.id.str Java property has been removed.</li>
  
<li>The unused yarn.policy.file Java property has been removed.</li>
  
<li>We now require bash v3 (released July 27, 2004) or better in order to take advantage of better regex handling and ${BASH_SOURCE}. POSIX sh will not work.</li>
  
<li>Support for &#x2013;script has been removed. We now use ${HADOOP_*_PATH} or ${HADOOP_PREFIX} to find the necessary binaries. (See other note regarding ${HADOOP_PREFIX} auto discovery.)</li>
  
<li>Non-existent classpaths, ld.so library paths, JNI library paths, etc, will be ignored and stripped from their respective environment settings.</li>
</ul>
<p>NEW FEATURES:</p>

<ul>
  
<li>Daemonization has been moved from *-daemon.sh to the bin commands via the &#x2013;daemon option. Simply use &#x2013;daemon start to start a daemon, &#x2013;daemon stop to stop a daemon, and &#x2013;daemon status to set $? to the daemon&#x2019;s status. The return code for status is LSB-compatible. For example, &#x2018;hdfs &#x2013;daemon start namenode&#x2019;.</li>
  
<li>It is now possible to override some of the shell code capabilities to provide site specific functionality without replacing the shipped versions. Replacement functions should go into the new hadoop-user-functions.sh file.</li>
  
<li>A new option called &#x2013;buildpaths will attempt to add developer build directories to the classpath to allow for in source tree testing.</li>
  
<li>Operations which trigger ssh connections can now use pdsh if installed. ${HADOOP_SSH_OPTS} still gets applied.</li>
  
<li>Added distch and jnipath subcommands to the hadoop command.</li>
  
<li>Shell scripts now support a &#x2013;debug option which will report basic information on the construction of various environment variables, java options, classpath, etc. to help in configuration debugging.</li>
</ul>
<p>BUG FIXES:</p>

<ul>
  
<li>${HADOOP_CONF_DIR} is now properly honored everywhere, without requiring symlinking and other such tricks.</li>
  
<li>${HADOOP_CONF_DIR}/hadoop-layout.sh is now documented with a provided hadoop-layout.sh.example file.</li>
  
<li>Shell commands should now work properly when called as a relative path, without ${HADOOP_PREFIX} being defined, and as the target of bash -x for debugging. If ${HADOOP_PREFIX} is not set, it will be automatically determined based upon the current location of the shell library. Note that other parts of the extended Hadoop ecosystem may still require this environment variable to be configured.</li>
  
<li>Operations which trigger ssh will now limit the number of connections to run in parallel to ${HADOOP_SSH_PARALLEL} to prevent memory and network exhaustion. By default, this is set to 10.</li>
  
<li>${HADOOP_CLIENT_OPTS} support has been added to a few more commands.</li>
  
<li>Some subcommands were not listed in the usage.</li>
  
<li>Various options on hadoop command lines were supported inconsistently. These have been unified into hadoop-config.sh. &#x2013;config is still required to be first, however.</li>
  
<li>ulimit logging for secure daemons no longer assumes /bin/bash but does assume bash is on the command line path.</li>
  
<li>Removed references to some Yahoo! specific paths.</li>
  
<li>Removed unused slaves.sh from YARN build tree.</li>
  
<li>Many exit states have been changed to reflect reality.</li>
  
<li>Shell level errors now go to STDERR. Before, many of them went incorrectly to STDOUT.</li>
  
<li>CDPATH with a period (.) should no longer break the scripts.</li>
  
<li>The scripts no longer try to chown directories.</li>
  
<li>If ${JAVA_HOME} is not set on OS X, it now properly detects it instead of throwing an error.</li>
</ul>
<p>IMPROVEMENTS:</p>

<ul>
  
<li>The *.out files are now appended instead of overwritten to allow for external log rotation.</li>
  
<li>The style and layout of the scripts is much more consistent across subprojects.</li>
  
<li>More of the shell code is now commented.</li>
  
<li>Significant amounts of redundant code have been moved into a new file called hadoop-functions.sh.</li>
  
<li>The various *-env.sh have been massively changed to include documentation and examples on what can be set, ramifications of setting, etc. for all variables that are expected to be set by a user.</li>
  
<li>There is now some trivial de-duplication and sanitization of the classpath and JVM options. This allows, amongst other things, for custom settings in *_OPTS for Hadoop daemons to override defaults and other generic settings (i.e., ${HADOOP_OPTS}). This is particularly relevant for Xmx settings, as one can now set them in _OPTS and ignore the heap specific options for daemons which force the size in megabytes.</li>
  
<li>Subcommands have been alphabetized in both usage and in the code.</li>
  
<li>All/most of the functionality provided by the sbin/* commands has been moved to either their bin/ equivalents or made into functions. The rewritten versions of these commands are now wrappers to maintain backward compatibility.</li>
  
<li>Usage information is given with the following options/subcommands for all scripts using the common framework: &#x2013;? -? ? &#x2013;help -help -h help</li>
  
<li>Several generic environment variables have been added to provide a common configuration for pids, logs, and their security equivalents. The older versions still act as overrides to these generic versions.</li>
  
<li>Groundwork has been laid to allow for custom secure daemon setup using something other than jsvc (e.g., pfexec on Solaris).</li>
  
<li>Scripts now test and report better error messages for various states of the log and pid dirs on daemon startup. Before, unprotected shell errors would be displayed to the user.</li>
</ul>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-8776">HADOOP-8776</a> | <i>Minor</i> | <b>Provide an option in test-patch that can enable / disable compiling native code</b></li>
</ul>
<p>test-patch.sh adds a new option &#x201c;&#x2013;build-native&#x201d;. When set to false native components are not built. When set to true native components are built. The default value is true.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-8124">HADOOP-8124</a> | <i>Major</i> | <b>Remove the deprecated Syncable.sync() method</b></li>
</ul>
<p>Remove the deprecated FSDataOutputStream constructor, FSDataOutputStream.sync() and Syncable.sync().</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-7659">HADOOP-7659</a> | <i>Minor</i> | <b>fs -getmerge isn&#x2019;t guaranteed to work well over non-HDFS filesystems</b></li>
</ul>
<p>Documented that the &#x201c;fs -getmerge&#x201d; shell command may not work properly over non HDFS-filesystem implementations due to platform-varying file list ordering.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-6857">HADOOP-6857</a> | <i>Major</i> | <b>FsShell should report raw disk usage including replication factor</b></li>
</ul>
<p>The output format of hadoop fs -du has been changed. It shows not only the file size but also the raw disk usage including the replication factor.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-9694">HDFS-9694</a> | <i>Major</i> | <b>Make existing DFSClient#getFileChecksum() work for striped blocks</b></li>
</ul>
<p>Makes the getFileChecksum API works with striped layout EC files. Checksum computation done by block level in the distributed fashion. The current API does not support to compare the checksum generated with normal file and the checksum generated for the same file but in striped layout.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-9640">HDFS-9640</a> | <i>Major</i> | <b>Remove hsftp from DistCp in trunk</b></li>
</ul>
<p>DistCp in Hadoop 3.0 no longer supports -mapredSSLConf option. Use global ssl-client.xml configuration file for swebhdfs file systems instead.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-9525">HDFS-9525</a> | <i>Blocker</i> | <b>hadoop utilities need to support provided delegation tokens</b></li>
</ul>
<p>If hadoop.token.files property is defined and configured to one or more comma-delimited delegation token files, Hadoop will use those token files to connect to the services as named in the token.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-9427">HDFS-9427</a> | <i>Critical</i> | <b>HDFS should not default to ephemeral ports</b></li>
</ul>
<p>The patch updates the HDFS default HTTP/RPC ports to non-ephemeral ports. The changes are listed below: Namenode ports: 50470 &#x2013;&gt; 9871, 50070 &#x2013;&gt; 9870, 8020 &#x2013;&gt; 9820 Secondary NN ports: 50091 &#x2013;&gt; 9869, 50090 &#x2013;&gt; 9868 Datanode ports: 50020 &#x2013;&gt; 9867, 50010 &#x2013;&gt; 9866, 50475 &#x2013;&gt; 9865, 50075 &#x2013;&gt; 9864</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-9278">HDFS-9278</a> | <i>Trivial</i> | <b>Fix preferredBlockSize typo in OIV XML output</b></li>
</ul>
<p>The preferred block size XML element has been corrected from &#x201c;\&lt;perferredBlockSize&gt;&#x201d; to &#x201c;\&lt;preferredBlockSize&gt;&#x201d;.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-9085">HDFS-9085</a> | <i>Trivial</i> | <b>Show renewer information in DelegationTokenIdentifier#toString</b></li>
</ul>
<p>The output of the &#x201c;hdfs fetchdt &#x2013;print&#x201d; command now includes the token renewer appended to the end of the existing token information. This change may be incompatible with tools that parse the output of the command.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-9070">HDFS-9070</a> | <i>Major</i> | <b>Allow fsck display pending replica location information for being-written blocks</b></li>
</ul>
<p>The output of fsck command for being written hdfs files had been changed. When using fsck against being written hdfs files with {{-openforwrite}} and {{-files -blocks -locations}}, the fsck output will include the being written block for replication files or being written block group for erasure code files.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-9057">HDFS-9057</a> | <i>Major</i> | <b>allow/disallow snapshots via webhdfs</b></li>
</ul>
<p>Snapshots can be allowed/disallowed on a directory via WebHdfs from users with superuser privilege.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-8981">HDFS-8981</a> | <i>Minor</i> | <b>Adding revision to data node jmx getVersion() method</b></li>
</ul>
<p>getSoftwareVersion method would replace original getVersion method, which returns the version string.</p>
<p>The new getVersion method would return both version string and revision string.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-8895">HDFS-8895</a> | <i>Major</i> | <b>Remove deprecated BlockStorageLocation APIs</b></li>
</ul>
<p>This removes the deprecated DistributedFileSystem#getFileBlockStorageLocations API used for getting VolumeIds of block replicas. Applications interested in the volume of a replica can instead consult BlockLocation#getStorageIds to obtain equivalent information.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-8591">HDFS-8591</a> | <i>Minor</i> | <b>Remove support for deprecated configuration key dfs.namenode.decommission.nodes.per.interval</b></li>
</ul>
<p>Related to the decommission enhancements in HDFS-7411, this change removes the deprecated configuration key &#x201c;dfs.namenode.decommission.nodes.per.interval&#x201d; which has been subsumed by the configuration key &#x201c;dfs.namenode.decommission.blocks.per.interval&#x201d;.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-8332">HDFS-8332</a> | <i>Major</i> | <b>DFS client API calls should check filesystem closed</b></li>
</ul>
<p>Users may need special attention for this change while upgrading to this version. Previously user could call some APIs(example: setReplication) wrongly even after closing the fs object. With this change DFS client will not allow any operations to call on closed fs objects. As calling fs operations on closed fs is not right thing to do, users need to correct the usage if any.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-8241">HDFS-8241</a> | <i>Minor</i> | <b>Remove unused NameNode startup option -finalize</b></li>
</ul>
<p>Remove -finalize option from hdfs namenode command.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-8135">HDFS-8135</a> | <i>Major</i> | <b>Remove the deprecated FSConstants class</b></li>
</ul>
<p>The FSConstants class has been deprecated since 0.23 and it is removed in the release.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-7985">HDFS-7985</a> | <i>Major</i> | <b>WebHDFS should be always enabled</b></li>
</ul>
<p>WebHDFS is mandatory and cannot be disabled.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-7460">HDFS-7460</a> | <i>Major</i> | <b>Rewrite httpfs to use new shell framework</b></li>
</ul>
<!-- markdown -->
<p>This deprecates the following environment variables:</p>

<table border="0" class="bodyTable">
  <thead>
    
<tr class="a">
      
<th align="left">Old </th>
      
<th align="left">New </th>
    </tr>
  </thead>
  <tbody>
    
<tr class="b">
      
<td align="left">HTTPFS_LOG </td>
      
<td align="left">HADOOP_LOG_DIR</td>
    </tr>
    
<tr class="a">
      
<td align="left">HTTPFS_CONFG </td>
      
<td align="left">HADOOP_CONF_DIR </td>
    </tr>
  </tbody>
</table>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-7302">HDFS-7302</a> | <i>Major</i> | <b>namenode -rollingUpgrade downgrade may finalize a rolling upgrade</b></li>
</ul>
<p>Remove &#x201c;downgrade&#x201d; from &#x201c;namenode -rollingUpgrade&#x201d; startup option since it may incorrectly finalize an ongoing rolling upgrade.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-7285">HDFS-7285</a> | <i>Major</i> | <b>Erasure Coding Support inside HDFS</b></li>
</ul>
<!-- markdown -->
<p>HDFS now provides native support for erasure coding (EC) to store data more efficiently. Each individual directory can be configured with an EC policy with command <tt>hdfs erasurecode -setPolicy</tt>. When a file is created, it will inherit the EC policy from its nearest ancestor directory to determine how its blocks are stored. Compared to 3-way replication, the default EC policy saves 50% of storage space while also tolerating more storage failures.</p>
<p>To support small files, the currently phase of HDFS-EC stores blocks in <i>striped</i> layout, where a logical file block is divided into small units (64KB by default) and distributed to a set of DataNodes. This enables parallel I/O but also decreases data locality. Therefore, the cluster environment and I/O workloads should be considered before configuring EC policies.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-7281">HDFS-7281</a> | <i>Major</i> | <b>Missing block is marked as corrupted block</b></li>
</ul>
<p>The patch improves the reporting around missing blocks and corrupted blocks.</p>

<ol style="list-style-type: decimal">
  
<li>A block is missing if and only if all DNs of its expected replicas are dead.</li>
  
<li>A block is corrupted if and only if all its available replicas are corrupted. So if a block has 3 replicas; one of the DN is dead, the other two replicas are corrupted; it will be marked as corrupted.</li>
  
<li>A new line is added to fsck output to display the corrupt block size per file.</li>
  
<li>A new line is added to fsck output to display the number of missing blocks in the summary section.</li>
</ol>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-6440">HDFS-6440</a> | <i>Major</i> | <b>Support more than 2 NameNodes</b></li>
</ul>
<p>This feature adds support for running additional standby NameNodes, which provides additional fault-tolerance. It is designed for a total of 3-5 NameNodes.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-6353">HDFS-6353</a> | <i>Major</i> | <b>Check and make checkpoint before stopping the NameNode</b></li>
</ul>
<p>Stopping the namenode on secure systems now requires the user be authenticated.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-6246">HDFS-6246</a> | <i>Minor</i> | <b>Remove &#x2018;dfs.support.append&#x2019; flag from trunk code</b></li>
</ul>
<p>Appends in HDFS can no longer be disabled.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5570">HDFS-5570</a> | <i>Major</i> | <b>Deprecate hftp / hsftp and replace them with webhdfs / swebhdfs</b></li>
</ul>
<p>Support for hftp and hsftp has been removed. They have superseded by webhdfs and swebhdfs.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5165">HDFS-5165</a> | <i>Minor</i> | <b>Remove the TotalFiles metrics</b></li>
</ul>
<p>Now TotalFiles metric is removed from FSNameSystem. Use FilesTotal instead.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5079">HDFS-5079</a> | <i>Major</i> | <b>Cleaning up NNHAStatusHeartbeat.State DatanodeProtocolProtos.</b></li>
</ul>
<p>This change affects wire-compatibility of the NameNode/DataNode heartbeat protocol.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-5033">HDFS-5033</a> | <i>Minor</i> | <b>Bad error message for fs -put/copyFromLocal if user doesn&#x2019;t have permissions to read the source</b></li>
</ul>
<p>&#x201c;Permission denied&#x201d; error message when unable to read local file for -put/copyFromLocal</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-3702">HDFS-3702</a> | <i>Minor</i> | <b>Add an option for NOT writing the blocks locally if there is a datanode on the same box as the client</b></li>
</ul>
<p>This patch will attempt to allocate all replicas to remote DataNodes, by adding local DataNode to the excluded DataNodes. If no sufficient replicas can be obtained, it will fall back to default block placement policy, which writes one replica to local DataNode.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-3034">HDFS-3034</a> | <i>Major</i> | <b>Remove the deprecated Syncable.sync() method</b></li>
</ul>
<p>Remove the deprecated DFSOutputStream.sync() method.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-2538">HDFS-2538</a> | <i>Minor</i> | <b>option to disable fsck dots</b></li>
</ul>
<p>fsck does not print out dots for progress reporting by default. To print out dots, you should specify &#x2018;-showprogress&#x2019; option.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-46">HDFS-46</a> | <i>Major</i> | <b>The namespace quota of root directory should not be Integer.MAX_VALUE</b></li>
</ul>
<p>Change default namespace quota of root directory from Integer.MAX_VALUE to Long.MAX_VALUE.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/MAPREDUCE-6613">MAPREDUCE-6613</a> | <i>Minor</i> | <b>Change mapreduce.jobhistory.jhist.format default from json to binary</b></li>
</ul>
<p>Default of &#x2018;mapreduce.jobhistory.jhist.format&#x2019; property changed from &#x2018;json&#x2019; to &#x2018;binary&#x2019;. Creates smaller, binary Avro .jhist files for faster JHS performance.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/MAPREDUCE-6526">MAPREDUCE-6526</a> | <i>Blocker</i> | <b>Remove usage of metrics v1 from hadoop-mapreduce</b></li>
</ul>
<p>LocalJobRunnerMetrics and ShuffleClientMetrics were updated to use Hadoop Metrics V2 framework.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/MAPREDUCE-6336">MAPREDUCE-6336</a> | <i>Major</i> | <b>Enable v2 FileOutputCommitter by default</b></li>
</ul>
<p>mapreduce.fileoutputcommitter.algorithm.version now defaults to 2.</p>
<p>In algorithm version 1:</p>

<ol style="list-style-type: decimal">
  
<li>
<p>commitTask renames directory  $joboutput/_temporary/$appAttemptID/_temporary/$taskAttemptID/  to  $joboutput/_temporary/$appAttemptID/$taskID/</p></li>
  
<li>
<p>recoverTask renames  $joboutput/_temporary/$appAttemptID/$taskID/  to  $joboutput/_temporary/($appAttemptID + 1)/$taskID/</p></li>
  
<li>
<p>commitJob merges every task output file in  $joboutput/_temporary/$appAttemptID/$taskID/  to  $joboutput/, then it will delete $joboutput/_temporary/  and write $joboutput/_SUCCESS</p></li>
</ol>
<p>commitJob&#x2019;s run time, number of RPC, is O(n) in terms of output files, which is discussed in MAPREDUCE-4815, and can take minutes. </p>
<p>Algorithm version 2 changes the behavior of commitTask, recoverTask, and commitJob.</p>

<ol style="list-style-type: decimal">
  
<li>
<p>commitTask renames all files in  $joboutput/_temporary/$appAttemptID/_temporary/$taskAttemptID/  to $joboutput/</p></li>
  
<li>
<p>recoverTask is a nop strictly speaking, but for  upgrade from version 1 to version 2 case, it checks if there  are any files in  $joboutput/_temporary/($appAttemptID - 1)/$taskID/  and renames them to $joboutput/</p></li>
  
<li>
<p>commitJob deletes $joboutput/_temporary and writes  $joboutput/_SUCCESS</p></li>
</ol>
<p>Algorithm 2 takes advantage of task parallelism and makes commitJob itself O(1). However, the window of vulnerability for having incomplete output in $jobOutput directory is much larger. Therefore, pipeline logic for consuming job outputs should be built on checking for existence of _SUCCESS marker.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/MAPREDUCE-6223">MAPREDUCE-6223</a> | <i>Major</i> | <b>TestJobConf#testNegativeValueForTaskVmem failures</b></li>
</ul>
<p><b>WARNING: No release note provided for this incompatible change.</b></p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/MAPREDUCE-5972">MAPREDUCE-5972</a> | <i>Trivial</i> | <b>Fix typo &#x2018;programatically&#x2019; in job.xml (and a few other places)</b></li>
</ul>
<p>Fix a typo. If a configuration is set through program, the source of the configuration is set to &#x2018;programmatically&#x2019; instead of &#x2018;programatically&#x2019; now.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/MAPREDUCE-5785">MAPREDUCE-5785</a> | <i>Major</i> | <b>Derive heap size or mapreduce.*.memory.mb automatically</b></li>
</ul>
<p>The memory values for mapreduce.map/reduce.memory.mb keys, if left to their default values of -1, will now be automatically inferred from the heap size value system property (-Xmx) specified for mapreduce.map/reduce.java.opts keys.</p>
<p>The converse is also done, i.e. if mapreduce.map/reduce.memory.mb values are specified, but no -Xmx is supplied for mapreduce.map/reduce.java.opts keys, then the -Xmx value will be derived from the former&#x2019;s value.</p>
<p>If neither is specified, then a default value of 1024 MB gets used.</p>
<p>For both these conversions, a scaling factor specified by property mapreduce.job.heap.memory-mb.ratio is used, to account for overheads between heap usage vs. actual physical memory usage.</p>
<p>Existing configs or job code that already specify both the set of properties explicitly would not be affected by this inferring change.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/MAPREDUCE-5653">MAPREDUCE-5653</a> | <i>Major</i> | <b>DistCp does not honour config-overrides for mapreduce.[map,reduce].memory.mb</b></li>
</ul>
<p>Prior to this change, distcp had hard-coded values for memory usage. Now distcp will honor memory settings in a way compatible with the rest of MapReduce.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/MAPREDUCE-4424">MAPREDUCE-4424</a> | <i>Minor</i> | <b>&#x2018;mapred job -list&#x2019; command should show the job name as well</b></li>
</ul>
<p>Now &#x201c;mapred job -list&#x201d; command displays the Job Name as well.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/MAPREDUCE-2841">MAPREDUCE-2841</a> | <i>Major</i> | <b>Task level native optimization</b></li>
</ul>
<p>Adds a native implementation of the map output collector. The native library will build automatically with -Pnative. Users may choose the new collector on a job-by-job basis by setting mapreduce.job.map.output.collector.class=org.apache.hadoop.mapred. nativetask.NativeMapOutputCollectorDelegator in their job configuration. For shuffle-intensive jobs this may provide speed-ups of 30% or more.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/MAPREDUCE-2632">MAPREDUCE-2632</a> | <i>Major</i> | <b>Avoid calling the partitioner when the numReduceTasks is 1.</b></li>
</ul>
<p><b>WARNING: No release note provided for this incompatible change.</b></p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/YARN-2428">YARN-2428</a> | <i>Trivial</i> | <b>LCE default banned user list should have yarn</b></li>
</ul>
<p>The user &#x2018;yarn&#x2019; is no longer allowed to run tasks for security reasons.</p>
<hr />

<ul>
  
<li><a class="externalLink" href="https://issues.apache.org/jira/browse/YARN-2355">YARN-2355</a> | <i>Major</i> | <b>MAX_APP_ATTEMPTS_ENV may no longer be a useful env var for a container</b></li>
</ul>
<p>Removed consumption of the MAX_APP_ATTEMPTS_ENV environment variable</p>
      </div>
    </div>
    <div class="clear">
      <hr/>
    </div>
    <div id="footer">
      <div class="xright">
        &#169;            2016
              Apache Software Foundation
            
                          - <a href="http://maven.apache.org/privacy-policy.html">Privacy Policy</a>.
        Apache Maven, Maven, Apache, the Apache feather logo, and the Apache Maven project logos are trademarks of The Apache Software Foundation.
      </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
  </body>
</html>
